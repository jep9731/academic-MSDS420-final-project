{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff95f816-52d5-4fd9-b4f3-2b8b162334b0",
   "metadata": {},
   "source": [
    "# Benchmarking Elasticsearch: NYC Congestion Pricing Traffic Analysis\n",
    "### By Group 3: Joshua Pasaye, Kelsey Kwon, and Anna Prunty-Burkart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ab2185-6552-4a7c-9a11-d13f9da873bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install elasticsearch==8.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05806f6-8162-4b04-a103-6aaf07d7bbbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1A\u001b[1B\u001b[0G\u001b[?25l[+] Running 1/1\n",
      " \u001b[32m✔\u001b[0m Container finalproject-elasticsearch-1  \u001b[32mRunning\u001b[0m                         \u001b[34m0.0s \u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# launch ElasticSearch in Docker container\n",
    "!docker compose -f docker-compose-elasticsearch.yml up -d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36ba03b6-e1c8-4d86-b37c-3e8e6c1bf978",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from elasticsearch import Elasticsearch, helpers\n",
    "from elasticsearch.helpers import parallel_bulk, BulkIndexError, scan\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4b0e4c-6180-498d-a399-bc8770063a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Create Elasticsearch client instance\n",
    "es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# Connection testing\n",
    "print(es.ping())   # should return True if connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6bf8f5b-7d0d-40a4-ad77-e8d3a522a7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average doc size ≈ 56.4 bytes\n",
      "Rows: 14,119\n",
      "Estimated index size: 0.00 GB\n"
     ]
    }
   ],
   "source": [
    "# For daily_ridership df: Calculate average doc size, number of rows, estimated index size \n",
    "# Load a small sample (10k rows)\n",
    "df_sample = pd.read_csv(\"UPDATED MTA_Daily_Ridership_and_Traffic__Beginning_2020_20250823_final.csv\", nrows=10000)\n",
    "\n",
    "# Convert sample to JSON bytes\n",
    "docs = df_sample.to_dict(orient=\"records\")\n",
    "json_bytes = sum(len(json.dumps(doc)) for doc in docs)\n",
    "\n",
    "avg_doc_size = json_bytes / len(docs)\n",
    "print(f\"Average doc size ≈ {avg_doc_size:.1f} bytes\")\n",
    "\n",
    "row_count = sum(1 for _ in open(\"UPDATED MTA_Daily_Ridership_and_Traffic__Beginning_2020_20250823_final.csv\")) - 1\n",
    "estimated_index_size_bytes = avg_doc_size * row_count\n",
    "\n",
    "print(f\"Rows: {row_count:,}\")\n",
    "print(f\"Estimated index size: {estimated_index_size_bytes / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b1ce343-db69-44e1-b941-1a926402e99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average doc size ≈ 419.9 bytes\n",
      "Rows: 2,322,432\n",
      "Estimated index size: 0.91 GB\n"
     ]
    }
   ],
   "source": [
    "# For crz df: Calculate average doc size, number of rows, estimated index size \n",
    "# Load a small sample (10k rows)\n",
    "df_sample = pd.read_csv(\"UPDATED MTA_Congestion_Relief_Zone_Vehicle_Entries__Beginning_2025_20250823.csv\", nrows=10000)\n",
    "\n",
    "# Convert sample to JSON bytes\n",
    "docs = df_sample.to_dict(orient=\"records\")\n",
    "json_bytes = sum(len(json.dumps(doc)) for doc in docs)\n",
    "\n",
    "avg_doc_size = json_bytes / len(docs)\n",
    "print(f\"Average doc size ≈ {avg_doc_size:.1f} bytes\")\n",
    "\n",
    "row_count = sum(1 for _ in open(\"UPDATED MTA_Congestion_Relief_Zone_Vehicle_Entries__Beginning_2025_20250823.csv\")) - 1\n",
    "estimated_index_size_bytes = avg_doc_size * row_count\n",
    "\n",
    "print(f\"Rows: {row_count:,}\")\n",
    "print(f\"Estimated index size: {estimated_index_size_bytes / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa65a01f-6f84-455b-9f3c-5fb825c40aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average doc size ≈ 335.4 bytes\n",
      "Rows: 11,608,864\n",
      "Estimated index size: 3.63 GB\n"
     ]
    }
   ],
   "source": [
    "# For tunnel_bridge_crossing df: Calculate average doc size, number of rows, estimated index size \n",
    "# Load a small sample (10k rows)\n",
    "df_sample = pd.read_csv(\"UPDATED MTA_Bridges_and_Tunnels_Hourly_Crossings__Beginning_2019_20250823.csv\", nrows=10000)\n",
    "\n",
    "# Convert sample to JSON bytes\n",
    "docs = df_sample.to_dict(orient=\"records\")\n",
    "json_bytes = sum(len(json.dumps(doc)) for doc in docs)\n",
    "\n",
    "avg_doc_size = json_bytes / len(docs)\n",
    "print(f\"Average doc size ≈ {avg_doc_size:.1f} bytes\")\n",
    "\n",
    "row_count = sum(1 for _ in open(\"UPDATED MTA_Bridges_and_Tunnels_Hourly_Crossings__Beginning_2019_20250823.csv\")) - 1\n",
    "estimated_index_size_bytes = avg_doc_size * row_count\n",
    "\n",
    "print(f\"Rows: {row_count:,}\")\n",
    "print(f\"Estimated index size: {estimated_index_size_bytes / (1024**3):.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ff533b5-2341-4f38-a1ee-783c186d251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load json file with select columns per dataset\n",
    "with open(\"nyc_congestion_datasets.json\", \"r\") as f:\n",
    "    nyc_congestion_datasets_select_col = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9917b97-d7fb-447f-8c14-73e0de799fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep data to ensure ES compatibility\n",
    "def actions_from_chunk(index_name, df):\n",
    "    # Replace infinite values with None and convert NaN values to None\n",
    "    df = df.replace([np.inf, -np.inf], None).where(pd.notnull(df), None)    \n",
    "    # Convert each DataFrame row into a dictionary for Elasticsearch bulk indexing\n",
    "    for doc in df.to_dict(orient=\"records\"):\n",
    "        yield {\"_index\": index_name, \"_source\": doc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b24f3377-2b8a-4f83-b3ae-67c88df496ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index CSV into Elasticsearch\n",
    "def index_csv(es, csv_path, index_name, columns, chunk_size=100000, bulk_size=20000):\n",
    "    # Delete index if it exists, then create a fresh one\n",
    "    if es.indices.exists(index=index_name):\n",
    "        es.indices.delete(index=index_name)\n",
    "    es.indices.create(\n",
    "        index=index_name,\n",
    "        settings={\n",
    "            \"refresh_interval\": \"-1\" # disable autorefresh\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Read CSV in chunks and send to Elasticsearch\n",
    "    for chunk in pd.read_csv(csv_path, chunksize=chunk_size, usecols=columns):\n",
    "        actions = actions_from_chunk(index_name, chunk)\n",
    "        list(parallel_bulk(es, actions, chunk_size=bulk_size, raise_on_error=False))\n",
    "\n",
    "    # Refresh index to make data searchable\n",
    "    es.indices.refresh(index=index_name)\n",
    "\n",
    "    print(f\"{index_name} indexed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ebed161-6dca-409d-a620-8b33d69be945",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daily_ridership indexed successfully.\n",
      "crz indexed successfully.\n",
      "tunnel_bridge_crossing indexed successfully.\n",
      "\n",
      " Total indexing time: 210.6 seconds\n"
     ]
    }
   ],
   "source": [
    "# Run indexing via json file\n",
    "start_all = time.time()\n",
    "\n",
    "for cfg in nyc_congestion_datasets_select_col:\n",
    "    index_csv(\n",
    "        es,\n",
    "        csv_path=cfg[\"csv_path\"],\n",
    "        index_name=cfg[\"index_name\"],\n",
    "        columns=cfg[\"columns\"]\n",
    "    )\n",
    "\n",
    "print(f\"\\n Total indexing time: {time.time() - start_all:.1f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e3403b-dd1f-464e-800c-2d5450c20b5f",
   "metadata": {},
   "source": [
    "##  Is NYC removing cars from Lower Manhattan?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860d9270-b773-4c86-94e2-47f9a01fa40d",
   "metadata": {},
   "source": [
    "### Traffic in the 7 months before the toll: May–Dec 2024 vs. same period in prior years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fef2034-dd1d-4c6b-9442-86961ead3833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 42.0 seconds\n",
      "   year  Traffic Count\n",
      "0  2019       62753970\n",
      "1  2020       46481171\n",
      "2  2021       60860738\n",
      "3  2022       63150116\n",
      "4  2023       64291873\n",
      "5  2024       64740227\n"
     ]
    }
   ],
   "source": [
    "# Measure time\n",
    "start_time = time.time()\n",
    "\n",
    "# filter tunnel_bridge_crossing by Direction \n",
    "query = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"wildcard\": {\"Direction.keyword\": \"*to Manhattan*\"}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use helpers.scan to retrieve all matching documents\n",
    "hits = []\n",
    "for doc in helpers.scan(\n",
    "    es,\n",
    "    index=\"tunnel_bridge_crossing\",\n",
    "    query={\"query\": query},\n",
    "    size=10000  # batch size per scroll\n",
    "):\n",
    "    hits.append(doc[\"_source\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(hits)\n",
    "\n",
    "# Create 'year' column from date\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['year'] = df['Date'].dt.year\n",
    "\n",
    "# Filter for May 1 to Dec 31 and removing the year 2025\n",
    "df = df[((df['Date'].dt.month > 5) | ((df['Date'].dt.month == 5) \n",
    "       & (df['Date'].dt.day >= 1))) \n",
    "       & (df['Date'].dt.year != 2025)]\n",
    "\n",
    "# Aggregate sum of Traffic Count by year\n",
    "daily_traffic_pre_tax_df = df.groupby('year')['Traffic Count'].sum().reset_index()\n",
    "daily_traffic_pre_tax_df = daily_traffic_pre_tax_df.sort_values('year')\n",
    "\n",
    "daily_traffic_pre_tax_df_elapsed_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Query took {daily_traffic_pre_tax_df_elapsed_time:.1f} seconds\")\n",
    "print(daily_traffic_pre_tax_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ea828-479a-47ba-9efa-fd91b005622a",
   "metadata": {},
   "source": [
    "### Traffic in the 7 months since the toll: Jan-July 205 vs. same period in prior years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3f2aec2-38aa-44d7-b4a1-13d88da8357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 43.0 seconds\n",
      "   year  Traffic Count\n",
      "0  2019       51934669\n",
      "1  2020       35336442\n",
      "2  2021       46547415\n",
      "3  2022       51466478\n",
      "4  2023       53105894\n",
      "5  2024       53412048\n",
      "6  2025       52462105\n"
     ]
    }
   ],
   "source": [
    "# Measure time\n",
    "start_time = time.time()\n",
    "\n",
    "# filter tunnel_bridge_crossing by Direction \n",
    "query = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"wildcard\": {\"Direction.keyword\": \"*to Manhattan*\"}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use helpers.scan to retrieve all matching documents\n",
    "hits = []\n",
    "for doc in helpers.scan(\n",
    "    es,\n",
    "    index=\"tunnel_bridge_crossing\",\n",
    "    query={\"query\": query},\n",
    "    size=10000  # batch size per scroll\n",
    "):\n",
    "    hits.append(doc[\"_source\"])\n",
    "\n",
    "\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(hits)\n",
    "\n",
    "# Create 'year' column from date\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['year'] = df['Date'].dt.year\n",
    "\n",
    "# Filter for Jan 5 to July 31\n",
    "df = df[\n",
    "    ((df['Date'].dt.month == 1) & (df['Date'].dt.day >= 5)) |\n",
    "    ((df['Date'].dt.month > 1) & (df['Date'].dt.month < 7)) | \n",
    "    ((df['Date'].dt.month == 7) & (df['Date'].dt.day <= 31))\n",
    "]\n",
    "\n",
    "# Aggregate sum of Traffic Count by year\n",
    "daily_traffic_post_tax_df = df.groupby('year')['Traffic Count'].sum().reset_index()\n",
    "daily_traffic_post_tax_df = daily_traffic_post_tax_df.sort_values('year')\n",
    "\n",
    "daily_traffic_post_tax_df_elapsed_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Query took {daily_traffic_post_tax_df_elapsed_time:.1f} seconds\")\n",
    "print(daily_traffic_post_tax_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50b6daf-eb93-444c-936d-0e4631aa13c5",
   "metadata": {},
   "source": [
    "## Did NYC subway ridership increase?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6eaa8a-17e4-4b3b-94b0-06f6e2a6f34b",
   "metadata": {},
   "source": [
    "### Compare average daily ridership across all modes of public transit since start of toll program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "019d80f9-af05-40c6-b43d-ad22eacf7529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 0.6 seconds\n",
      "          Mode         Count\n",
      "8       Subway  3.488259e+06\n",
      "2          Bus  1.235365e+06\n",
      "1           BT  9.223840e+05\n",
      "3  CBD Entries  5.563550e+05\n",
      "4  CRZ Entries  4.912280e+05\n",
      "5         LIRR  2.176223e+05\n",
      "6          MNR  1.862816e+05\n",
      "0          AAR  3.644817e+04\n",
      "7          SIR  5.808284e+03\n"
     ]
    }
   ],
   "source": [
    "# Measure time\n",
    "start_time = time.time()\n",
    "\n",
    "# Filter to January 5-July 31, 2025\n",
    "query = {\n",
    "    \"range\": {\n",
    "        \"Date\": {\n",
    "            \"gte\": \"2025-01-05T00:00:00\", \n",
    "            \"lt\": \"2025-08-01T00:00:00\"    \n",
    "        }  \n",
    "    }\n",
    "}\n",
    "\n",
    "# Use helpers.scan to retrieve all matching documents\n",
    "hits = []\n",
    "for doc in helpers.scan(\n",
    "    es,\n",
    "    index=\"daily_ridership\",\n",
    "    query={\"query\": query},\n",
    "):\n",
    "    hits.append(doc[\"_source\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(hits)\n",
    "\n",
    "# Aggregate average daily ridershipt by transit mode\n",
    "ridership_mode_df = df.groupby('Mode')['Count'].mean().reset_index()\n",
    "ridership_mode_df = ridership_mode_df.sort_values('Count', ascending=False)\n",
    "\n",
    "ridership_mode_df_elapsed_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Query took {ridership_mode_df_elapsed_time:.1f} seconds\")\n",
    "print(ridership_mode_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d036b9e-6793-4bd5-87bd-6beb0727ab02",
   "metadata": {},
   "source": [
    "### Average daily Subway ridership pre-toll by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3f546eea-33bf-4581-b3f1-e0a8ca6a8c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 0.1 seconds\n",
      "   year         Count\n",
      "0  2020  1.209467e+06\n",
      "1  2021  2.081672e+06\n",
      "2  2022  2.773989e+06\n",
      "3  2023  3.151280e+06\n",
      "4  2024  3.262847e+06\n"
     ]
    }
   ],
   "source": [
    "# Compare average daily ridership across all modes of public transit since start of toll program\n",
    "\n",
    "# Measure time\n",
    "start_time = time.time()\n",
    "\n",
    "# query index, filter to January 5-July 31, 2025\n",
    "query = {\n",
    "    \"bool\": { \n",
    "        \"must\": [\n",
    "            {\"term\": {\"Mode.keyword\": \"Subway\"}}\n",
    "        ],\n",
    "        \"must_not\": [\n",
    "            {\n",
    "                \"range\": {\n",
    "                    \"Date\": {\n",
    "                        \"gte\": \"2025-01-01T00:00:00\",\n",
    "                        \"lt\": \"2025-08-01T00:00:00\"  \n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use helpers.scan to retrieve all matching documents\n",
    "hits = []\n",
    "for doc in helpers.scan(\n",
    "    es,\n",
    "    index=\"daily_ridership\",\n",
    "    query={\"query\": query},  \n",
    "):\n",
    "    hits.append(doc[\"_source\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(hits)\n",
    "\n",
    "# Create 'month' column from date\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['year'] = df['Date'].dt.year\n",
    "\n",
    "# Aggregate average daily ridership by transit mode\n",
    "# Changed 'Month' to 'month' to match the column name created above\n",
    "subway_yearly_ridership_df = df.groupby('year')['Count'].mean().reset_index()\n",
    "\n",
    "subway_yearly_ridership_df_elapsed_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Query took {subway_yearly_ridership_df_elapsed_time:.1f} seconds\")\n",
    "print(subway_yearly_ridership_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4270f511-f999-4a64-8426-f7eb40095b4c",
   "metadata": {},
   "source": [
    "### Average daily Subway ridership post-toll by month\n",
    "Compare average daily ridership across all modes of public transit since start of toll program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "346230c0-976a-4ed1-b1ee-8f433bffb670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 0.0 seconds\n",
      "   month         Count\n",
      "0      1  3.257162e+06\n",
      "1      2  3.361130e+06\n",
      "2      3  3.494515e+06\n",
      "3      4  3.666954e+06\n",
      "4      5  3.627925e+06\n",
      "5      6  3.551575e+06\n",
      "6      7  3.424240e+06\n"
     ]
    }
   ],
   "source": [
    "# Measure time\n",
    "start_time = time.time()\n",
    "\n",
    "# filter to January 5-July 31, 2025\n",
    "query = {\n",
    "    \"bool\": { \n",
    "        \"must\": [\n",
    "            {\n",
    "                \"term\": {\n",
    "                    \"Mode.keyword\": \"Subway\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"range\": {\n",
    "                    \"Date\": {\n",
    "                        \"gte\": \"2025-01-05T00:00:00\", \n",
    "                        \"lt\": \"2025-08-01T00:00:00\"    \n",
    "                    }  \n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Use helpers.scan to retrieve all matching documents\n",
    "hits = []\n",
    "for doc in helpers.scan(\n",
    "    es,\n",
    "    index=\"daily_ridership\",\n",
    "    query={\"query\": query},  \n",
    "    size=10000  # batch size per scroll\n",
    "):\n",
    "    hits.append(doc[\"_source\"])\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(hits)\n",
    "\n",
    "# Create 'month' column from date\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['month'] = df['Date'].dt.month \n",
    "\n",
    "# Aggregate average daily ridership by transit mode\n",
    "# Changed 'Month' to 'month' to match the column name created above\n",
    "subway_monthly_ridership_df = df.groupby('month')['Count'].mean().reset_index()\n",
    "\n",
    "subway_monthly_ridership_df_elapsed_time = time.time() - start_time\n",
    "\n",
    "# Output\n",
    "print(f\"Query took {subway_monthly_ridership_df_elapsed_time:.1f} seconds\")\n",
    "print(subway_monthly_ridership_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998da910-e1e7-4a05-8c04-5cfb082ae1e2",
   "metadata": {},
   "source": [
    "##  Is NYC Adding Revenue? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c67e7da-1434-4757-a89e-5a8015148f94",
   "metadata": {},
   "source": [
    "### Estimated revenue by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4c16a9a-74bc-42cb-8576-1d1f595a327d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 27.2 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>est_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.162038e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7.382396e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8.432042e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.369648e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.798363e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>8.350449e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>8.433866e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   month   est_revenue\n",
       "0      1  7.162038e+07\n",
       "1      2  7.382396e+07\n",
       "2      3  8.432042e+07\n",
       "3      4  8.369648e+07\n",
       "4      5  8.798363e+07\n",
       "5      6  8.350449e+07\n",
       "6      7  8.433866e+07"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure time\n",
    "start_time = time.time()\n",
    "\n",
    "# Pull all documents from crz index\n",
    "hits = []\n",
    "for doc in scan(es, index=\"crz\"):\n",
    "    hits.append(doc[\"_source\"])\n",
    "\n",
    "df = pd.DataFrame(hits)\n",
    "\n",
    "# Create function for est_revenue column\n",
    "def calculate_revenue(row):\n",
    "    vehicle_class = row['Vehicle Class']\n",
    "    time_period = row['Time Period']\n",
    "    entries = row['CRZ Entries']\n",
    "\n",
    "    # Assign rate based on vehicle class and time period\n",
    "    if vehicle_class == '1 - Cars, Pickups and Vans' and time_period == 'Peak':\n",
    "        rate = 9.00\n",
    "    elif vehicle_class == '1 - Cars, Pickups and Vans' and time_period == 'Overnight':\n",
    "        rate = 2.25\n",
    "    elif vehicle_class == '5 - Motorcycles' and time_period == 'Peak':\n",
    "        rate = 4.50\n",
    "    elif vehicle_class == '5 - Motorcycles' and time_period == 'Overnight':\n",
    "        rate = 1.05\n",
    "    elif vehicle_class in ['2 - Single-Unit Trucks', '4 - Buses'] and time_period == 'Peak':\n",
    "        rate = 14.40\n",
    "    elif vehicle_class in ['2 - Single-Unit Trucks', '4 - Buses'] and time_period == 'Overnight':\n",
    "        rate = 3.60\n",
    "    elif vehicle_class == '3 - Multi-Unit Trucks' and time_period == 'Peak':\n",
    "        rate = 21.60\n",
    "    elif vehicle_class == '3 - Multi-Unit Trucks' and time_period == 'Overnight':\n",
    "        rate = 5.40\n",
    "    elif vehicle_class == 'TLC Taxi/FHV':\n",
    "        rate = 1.125\n",
    "    else:\n",
    "        rate = 0.0\n",
    "\n",
    "    # Calculate estimated revenue\n",
    "    return entries * rate\n",
    "\n",
    "df['est_revenue'] = df.apply(calculate_revenue, axis=1)\n",
    "\n",
    "# Create dataframe with estimated revenue per month\n",
    "\n",
    "# Ensure Toll Date is datetime\n",
    "df['Toll Date'] = pd.to_datetime(df['Toll Date'])\n",
    "\n",
    "# Extract month\n",
    "df['month'] = df['Toll Date'].dt.month\n",
    "\n",
    "# Filter for months before August\n",
    "df_before_august = df[df['month'] < 8]\n",
    "\n",
    "# Group by month and sum revenue\n",
    "monthly_revenue_df = df_before_august.groupby('month')['est_revenue'].sum().reset_index()\n",
    "\n",
    "monthly_revenue_df_elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Query took {monthly_revenue_df_elapsed_time:.1f} seconds\")\n",
    "monthly_revenue_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211442d-68fc-4fc4-a8b1-2deb2c267b02",
   "metadata": {},
   "source": [
    "### Estimated revenue by vehicle class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca7a104f-3497-4726-8a46-1f71eb97fdd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query took 0.2 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vehicle Class</th>\n",
       "      <th>est_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 - Cars, Pickups and Vans</td>\n",
       "      <td>4.497279e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2 - Single-Unit Trucks</td>\n",
       "      <td>4.811358e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3 - Multi-Unit Trucks</td>\n",
       "      <td>4.861388e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 - Buses</td>\n",
       "      <td>2.267271e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5 - Motorcycles</td>\n",
       "      <td>1.516298e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TLC Taxi/FHV</td>\n",
       "      <td>4.239614e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Vehicle Class   est_revenue\n",
       "0  1 - Cars, Pickups and Vans  4.497279e+08\n",
       "1      2 - Single-Unit Trucks  4.811358e+07\n",
       "2       3 - Multi-Unit Trucks  4.861388e+06\n",
       "3                   4 - Buses  2.267271e+07\n",
       "4             5 - Motorcycles  1.516298e+06\n",
       "5                TLC Taxi/FHV  4.239614e+07"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Measure time\n",
    "start_time = time.time()\n",
    "\n",
    "# Group by month and sum revenue\n",
    "revenue_vehicle_class_df = df_before_august.groupby('Vehicle Class')['est_revenue'].sum().reset_index()\n",
    "\n",
    "revenue_vehicle_class_df_elapsed_time = time.time() - start_time\n",
    "\n",
    "print(f\"Query took {revenue_vehicle_class_df_elapsed_time:.1f} seconds\")\n",
    "revenue_vehicle_class_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14200fa3-b721-4bbf-9bb7-9a4cdf9b43a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ridership_mode_df query took 42.0 seconds \n",
      "\n",
      "daily_traffic_post_tax_df query took 43.0 seconds \n",
      "\n",
      "ridership_mode_df query took 0.64 seconds \n",
      "\n",
      "subway_yearly_ridership_df query took 0.08 seconds \n",
      "\n",
      "subway_monthly_ridership_df query took 0.03 seconds \n",
      "\n",
      "monthly_revenue_df query took 27.2 seconds \n",
      "\n",
      "revenue_vehicle_class_df query took 0.18 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print\n",
    "print(f'ridership_mode_df query took {daily_traffic_pre_tax_df_elapsed_time:.1f} seconds \\n')\n",
    "print(f'daily_traffic_post_tax_df query took {daily_traffic_post_tax_df_elapsed_time:.1f} seconds \\n')\n",
    "print(f'ridership_mode_df query took {ridership_mode_df_elapsed_time:.2f} seconds \\n')\n",
    "print(f'subway_yearly_ridership_df query took {subway_yearly_ridership_df_elapsed_time:.2f} seconds \\n')\n",
    "print(f'subway_monthly_ridership_df query took {subway_monthly_ridership_df_elapsed_time:.2f} seconds \\n')\n",
    "print(f'monthly_revenue_df query took {monthly_revenue_df_elapsed_time:.1f} seconds \\n')\n",
    "print(f'revenue_vehicle_class_df query took {revenue_vehicle_class_df_elapsed_time:.2f} seconds \\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
